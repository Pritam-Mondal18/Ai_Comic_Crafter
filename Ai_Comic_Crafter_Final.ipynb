{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpTKbejT6RxjWlMBbft9iP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pritam-Mondal18/Ai_Comic_Crafter/blob/main/Ai_Comic_Crafter_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WHB5mn0v0mE",
        "outputId": "f1e9c98f-1ad6-452a-e258-d7d3cf5d0627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.32.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX19lMuXv_go",
        "outputId": "3825e3eb-7927-41b4-e252-b921e9bdf689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-linux_x86_64.whl size=6008054 sha256=d2bf5784ee0038e5c96b8b1711e609fa599630c3eef2a62a984580e6ac1469f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/03/66/eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"YOUR_ACCESS-KEY\")\n"
      ],
      "metadata": {
        "id": "wD35cxIpwDhK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Set Page Configuration\n",
        "st.set_page_config(page_title=\"AI Comic Crafter\", page_icon=\"🤺\", layout=\"wide\")\n",
        "\n",
        "# Enhanced Title Section\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <h1 style='text-align: center; color: #FF5733;'>🎨 AI Comic Crafter 🦸</h1>\n",
        "    <p style='text-align: center; font-size:18px;'>Turn your ideas into stunning comic stories with AI!</p>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# Load Stable Diffusion Model (Hugging Face Diffusers)\n",
        "@st.cache_resource\n",
        "def load_sd_model():\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "    )\n",
        "    pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return pipe\n",
        "\n",
        "pipe = load_sd_model()\n",
        "\n",
        "# Load a Smaller LLM Model (GPT-2 for Text Generation)\n",
        "@st.cache_resource\n",
        "def load_llm():\n",
        "    return pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "llm = load_llm()\n",
        "\n",
        "# Sidebar Settings with Better UI\n",
        "theme_color = \"#FF5733\"\n",
        "st.sidebar.markdown(f\"<h2 style='color: {theme_color};'>📜 Story Settings</h2>\", unsafe_allow_html=True)\n",
        "genre = st.sidebar.selectbox(\"Choose a Genre\", [\"Superhero\", \"Fantasy\", \"Sci-Fi\", \"Mystery\"])\n",
        "style = st.sidebar.selectbox(\"Comic Style\", [\"Manga\", \"Cartoon\", \"Realistic\", \"Vintage\"])\n",
        "collage_format = st.sidebar.selectbox(\"Collage Format\", [\"2x2 Grid\", \"Vertical Strip\", \"Horizontal Strip\"])\n",
        "num_panels = 4  # Fixed to match the 4 story sections\n",
        "\n",
        "# Story Input\n",
        "st.markdown(\"<h3>✍️ Write Your Comic Story</h3>\", unsafe_allow_html=True)\n",
        "introduction = st.text_area(\"Introduction\", \"\")\n",
        "storyline = st.text_area(\"Storyline\", \"\")\n",
        "climax = st.text_area(\"Climax\", \"\")\n",
        "moral = st.text_area(\"Moral\", \"\")\n",
        "\n",
        "# Generate Story Using LLM\n",
        "if st.button(\"🤖 Generate Story with AI\", help=\"Let AI generate a comic story for you!\"):\n",
        "    with st.spinner(\"Generating story elements...\"):\n",
        "        intro_text = llm(f\"Generate an introduction for a {genre} comic story.\", max_length=50)[0]['generated_text']\n",
        "        story_text = llm(f\"Generate the main storyline for a {genre} comic story.\", max_length=100)[0]['generated_text']\n",
        "        climax_text = llm(f\"Generate a climax for a {genre} comic story.\", max_length=50)[0]['generated_text']\n",
        "        moral_text = llm(f\"Generate a moral for a {genre} comic story.\", max_length=40)[0]['generated_text']\n",
        "\n",
        "    introduction = st.text_area(\"Introduction\", intro_text)\n",
        "    storyline = st.text_area(\"Storyline\", story_text)\n",
        "    climax = st.text_area(\"Climax\", climax_text)\n",
        "    moral = st.text_area(\"Moral\", moral_text)\n",
        "\n",
        "# Function to Generate Comic-Style Images\n",
        "def generate_comic_images(prompts):\n",
        "    images = []\n",
        "    for prompt in prompts:\n",
        "        panel_prompt = f\"{prompt}, {style} comic-style, highly detailed, vibrant colors\"\n",
        "        image = pipe(prompt=panel_prompt).images[0]  # Generate image\n",
        "        images.append(image)\n",
        "    return images\n",
        "\n",
        "# Create Collage\n",
        "def create_collage(images, format_type):\n",
        "    widths, heights = zip(*(img.size for img in images))\n",
        "\n",
        "    if format_type == \"2x2 Grid\":\n",
        "        collage_width = max(widths) * 2\n",
        "        collage_height = max(heights) * 2\n",
        "        collage = Image.new(\"RGB\", (collage_width, collage_height))\n",
        "        positions = [(0, 0), (max(widths), 0), (0, max(heights)), (max(widths), max(heights))]\n",
        "    elif format_type == \"Vertical Strip\":\n",
        "        collage_width = max(widths)\n",
        "        collage_height = sum(heights)\n",
        "        collage = Image.new(\"RGB\", (collage_width, collage_height))\n",
        "        positions = [(0, sum(heights[:i])) for i in range(len(images))]\n",
        "    else:  # Horizontal Strip\n",
        "        collage_width = sum(widths)\n",
        "        collage_height = max(heights)\n",
        "        collage = Image.new(\"RGB\", (collage_width, collage_height))\n",
        "        positions = [(sum(widths[:i]), 0) for i in range(len(images))]\n",
        "\n",
        "    for img, pos in zip(images, positions):\n",
        "        collage.paste(img, pos)\n",
        "\n",
        "    return collage\n",
        "\n",
        "# Generate Story & Images\n",
        "if st.button(\"🤺 Generate Comic\", help=\"Create your AI-powered comic panels!\"):\n",
        "    with st.spinner(\"Generating Comic Panels... 🖌️\"):\n",
        "        images = generate_comic_images([introduction, storyline, climax, moral])\n",
        "        collage = create_collage(images, collage_format)\n",
        "        collage_path = \"comic_collage.png\"\n",
        "        collage.save(collage_path)\n",
        "\n",
        "    st.image(collage_path, caption=\"🎭 Your AI-Generated Comic Collage! 🎭\")\n",
        "\n",
        "    # Zip and provide download button\n",
        "    zip_buffer = BytesIO()\n",
        "    with zipfile.ZipFile(zip_buffer, \"w\") as zip_file:\n",
        "        zip_file.write(collage_path)\n",
        "    zip_buffer.seek(0)\n",
        "    st.sidebar.download_button(\n",
        "        label=\"💽 Download Comic Collage\",\n",
        "        data=zip_buffer,\n",
        "        file_name=\"comic_collage.zip\",\n",
        "        mime=\"application/zip\"\n",
        "    )\n",
        "\n",
        "# Footer\n",
        "st.sidebar.markdown(\"<hr>\", unsafe_allow_html=True)\n",
        "st.sidebar.markdown(\"✨ <b>Powered by AI & Comic-Builders 🚀</b>\", unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omO2mjicwHok",
        "outputId": "ddf062cd-f0cb-4eed-aff3-07d5f2030148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "jLFdjk8fwIvi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken YOUR_ACCESS-KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGUMw1FYxr-A",
        "outputId": "8f69b760-e050-4ed0-c5df-807fdb60f530"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Run Streamlit in the background\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "# Expose port 8501 (Streamlit's default port)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFQgFDeVwLzk",
        "outputId": "73342fc2-1d98-4f12-9783-c667cb7358c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://f5db-34-125-144-95.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}